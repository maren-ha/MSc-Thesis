\chapter{Discussion}\label{chap:discussion}
\fancyhead[LO]{\nouppercase{\leftmark}}

In this thesis, I have adapted the architecture of the variational autoencoder, a generative deep learning framework, to develop a model that can identify the central factors of variation in temporal development patterns and recover them in a non-linear and unsupervised fashion. I have constrained the latent space to model smooth trajectories by integrating an ODE system and augmented the model with another neural network used to infer individual-specific ODE parameters from additional baseline variables.
Furthermore, I have extended the model to train on batches of similar individuals, using combined measurements of other individuals from the batch as proxy information on the common trajectory at multiple time points. 

Inspired by a data scenario from a NAKO sub study, I have devised a simulation design where data are generated from distinct underlying temporal developments with random measurement noise at a common baseline time point and an irregularly sampled individual second time point. Then, the model has been applied and evaluated on these simulated data from both a linear and a non-linear ODE system with two unknown parameters and trained on batches of similar individuals on data from a linear system with four unknown parameters. I have compared different simulation scenarios of baseline information and different numbers of informative baseline variables and investigated the model performance for different levels of simulated measurement noise and across several training runs.

Overall, it could be shown that the proposed ODE-VAE model can recover the distinct underlying development patterns and infer individual-specific ODE parameters in various simulated data settings and accurately identify groups of individuals with similar trajectories. In conclusion, it thus provides an individual-level understanding of the temporal dynamics underlying individuals' developments and, rather than estimating average effects, has the potential to plan interventions based on the knowledge of full individual-specific dynamical systems.

With respect to related research, the main novelties of my method are the employment of batches of similar individuals to get proxy information on additional measurement time points and training the model in an iterative expectation-maximisation-like procedure to be able to afford more ODE parameters and thus model more complex dynamics. Also, the idea to infer individual-specific ODE parameter sets from additional baseline information has been introduced. What further differentiates my approach from, e.g., the latent time-series models in \cite{Chen2018} and \cite{Rubanova2019} is solving the ODEs at the level of the latent representation and implicitly conditioning the smooth mean obtained from solving the ODE on the data from the second measurement time point by adapting the training objective to explicitly encourage consistency of the latent representation means before and after solving the ODE. 
 
The main limitations of the method are that some knowledge on the underlying dynamics is required to define the general structure and dimensionality of the ODE system and the general sensitivity of the model to noisy information in the time-dependent and baseline variables as well as to how the data is scaled with respect to the $\mathcal{N}(0,1)$-prior. Additionally, even for only moderately complex scenarios, the model performance is subject to substantial variability for different random initialisations of the model parameters. In its current form, the method is restricted to a rather specific setting. 

For future research, it would thus be promising to leverage the method to model more complex or higher-dimensional dynamical systems, possibly also with more measurement time points, and to more thoroughly investigate its performance by defining rigorous evaluation criteria and averaging over many training runs. Finally, it would be crucial to test and evaluate the model performance on real-world datasets such as the NAKO study, which could then guide the modelling of more complex scenarios based on results from real data once they become available.